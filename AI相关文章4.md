## 文章：从语言模型到多模态模型，到带有结构空间的AGI

这只是一篇初步的想法，在ai的辅助下完成，可能是不正确的，很多地方可能还没严谨地给出具体的定义，仅供参考。

在文章开始之前，我们先来考虑一个基本问题：为什么对人类来说有时候用“文字对应的图像”推理，会比直接用文字推理，会更容易理解？

以“诱导拓扑”或者“几乎处处收敛”这样的概念为例，这些概念如果不想象对应的图像，对人类来说是很难理解的。

为什么呢？因为视觉系统的表征空间维度更高、结构更连续、可并行，可直接承载几何与因果关系；而语言是线性、低维、离散、强压缩的编码，推理难度天然更大。语言是一种压缩后的符号，需要你在脑内“解压 → 构图 → 操作结构”。

比如房间里有一张桌子，桌子上有一个杯子，杯子左边有一支笔…这一句话的概念，对语言模型，需要一个建模的过程，图像模型更容易一次性获得空间结构，而语言需要逐步构建。

虽然我们看到纯llm+RL，得益于llm远比人类大的工作记忆，以及足够大的参数中强化学习训练出的优质长期记忆，可以实现足够强的数学大模型，但是如果能让ai拥有更优的推理方式，可能可以让ai的能力更上一层楼。

但是视觉空间就一定是最好的推理空间吗？不是这样的，有时候人类用语言符号推导逻辑，反而比用图像更方便。同时，有时候仅以图像是无法想象、推理高维、抽象的几何空间的。那到底在哪里推理最优呢？答案可能是——一种新的结构空间。

真正的推理发生在结构空间，而不是在语言空间。图像更接近结构空间，所以人类在图像中推理更自然。但是，人类能利用的图像推理是有局限的——人想象不了更高的维度，只能通过语言符号、图像的结合来推导更高深的数学。图像之所以好用，是因为它天然具备一种“几何结构”：连续性、邻接、几何不变性。“视觉空间”其实是“结构空间”的一种子空间。

接下来我们考虑如何构建结构空间，或者说，训练一个带有结构空间的大模型。

我们知道，所谓llm生成模型，本质上是输出下一个词，而所谓视觉AI，就是用大量的图片像素数据与对应的标签训练图片与文本的关联，或者通过视频之前的帧生成下一帧，以训练图像在时序上的推理能力。那结构空间训练的AI，很显然就是训练结构与其附带的文本、图像标签的对应关系，以及结构在时序上的变换模式。第一层结构，是从现实数据中的不变关系中自然生长出来的。不过，如果可以在结构空间上直接推理，可能不需要训练标签。或者结构出现后，再学习其与文本、图像之间的对应关系。

视觉之所以能形成，是因为世界的结构是稳定的。大脑只是在寻找那些稳定不变的结构。训练结构系统不是训练图片，而是训练“结构之间的变化与不变性”。

结构系统的训练，就是：让 AI 在“结构空间”里进行自监督预测、对比学习、生成与自洽校验。

那么，如何找到已有的结构呢？我们需要用特定的损失函数去寻找“让推理更容易”的好的结构。如图、树、森林（关系结构），拓扑（几何/连续结构），群与同构（代数不变性结构）。我们要学习这些结构的变换模式，以及这些结构变换中的不变量，不同结构类型对应不同类型的不变性。这里的结构不限于数学意义上的结构（如图、树、拓扑、群），还包括逻辑链条、概念关联、推理步骤、模式组合方式等更一般的结构。

下面是几种可能的损失函数：

Loss 1：不变性损失:在输入变换后，内部结构不变。

Loss 2：组合最优性损失:组合最优性意味着：存在某种结构，使得推理链的描述长度最小，从而结构会自发出现。组合结构更省描述长度。

Loss 3：自监督结构预测:给定当前结构，预测下一步推理结构，看准确率。

结构系统的训练来源有以下几个方面：

1、自监督的「逻辑序列 → 下一个结构」预测（结构演化模型）。如预测下一个关系图结构、下一个推理步骤的结构。下一结构是结构之间的组合、扩展、映射、缩并的下一步状态（state）。例如概念之间关系图的下一步变化、推理树的下一层、映射的下一次组合——统称为下一结构。

2、不同结构之间的“等价性”学习（学习不变量）。哪些结构的变换不会改变“意义”？就像视觉系统学习“物体旋转后还是同一个物体”。模型通过对比学习去学学习哪些结构是同构的。诸如两个逻辑链能否被统一为同一个模式？两个概念是否存在同构？

3、让系统自己“提出结构”（生成定义、概念、关系）。结构系统训练的第三方向是

生成结构，再检验结构是否自洽。

从理论上讲，在成熟的结构空间中，AI 有可能自行提出定义，发明全新的数学。在成熟的结构空间中，标签可能不是语言，而是不变模式本身；语言只是人类对这些结构的外层描述，而 AGI 的内部结构空间可能包含“我们目前没有词能表达”的结构类型。

编辑于 2025-11-30 13:52